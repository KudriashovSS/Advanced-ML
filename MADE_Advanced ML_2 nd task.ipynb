{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, pickle\n",
    "from collections import Counter\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import clone\n",
    "from scipy.sparse import vstack, hstack\n",
    "from scipy.stats.stats import spearmanr\n",
    "from scipy.stats.stats import kendalltau\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tournaments = pickle.load(open('tournaments.pkl', 'rb'))\n",
    "results = pickle.load(open('results.pkl', 'rb'))\n",
    "players = pickle.load(open('players.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Прочитайте и проанализируйте данные, выберите турниры, в которых есть данные о составах команд и повопросных результатах (поле mask в results.pkl). Для унификации предлагаю: \n",
    "### 1.1 взять в тренировочный набор турниры с dateStart из 2019 года;  \n",
    "### 1.2 в тестовый — турниры с dateStart из 2020 года.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tournaments                  = pd.DataFrame(tournaments.values()).set_index(\"id\")\n",
    "df_tournaments[\"year\"]          = df_tournaments[\"dateStart\"].apply(lambda x: int(x[:4]))\n",
    "# 1.1\n",
    "df_train_tournaments            = df_tournaments[df_tournaments[\"year\"] == 2019]\n",
    "# 1.2\n",
    "df_test_tournaments             = df_tournaments[df_tournaments[\"year\"] == 2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_players                      = pd.DataFrame(players.values()).set_index(\"id\")\n",
    "df_players_indexed              = df_players.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Постройте baseline-модель на основе линейной или логистической регрессии, которая будет обучать рейтинг-лист игроков. Замечания и подсказки:\n",
    "### 2.1 повопросные результаты — это фактически результаты броска монетки, и их предсказание скорее всего имеет отношение к бинарной классификации;\n",
    "### 2.2 в разных турнирах вопросы совсем разного уровня сложности, поэтому модель должна это учитывать; скорее всего, модель должна будет явно обучать не только силу каждого игрока, но и сложность каждого вопроса;\n",
    "### 2.3 для baseline-модели можно забыть о командах и считать, что повопросные результаты команды просто относятся к каждому из её игроков.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution: Train Logistic Regression Model on one variable of One Hot Vector of Player Level and Question Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result: Table contains famous names:\n",
    "#####    'Stanislav Mereminskiy'\n",
    "#####      'Mikhail Levandovskiy'\n",
    "#####      'Ilya Novikov'\n",
    "#####      'Sergey Nikolenko'\n",
    "#####      'Yulia Arkhangelskaya'\n",
    "#####      'Nikolay Krapil'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Качество рейтинг-системы оценивается качеством предсказаний результатов турниров. Но сами повопросные результаты наши модели предсказывать вряд ли смогут, ведь неизвестно, насколько сложными окажутся вопросы в будущих турнирах; да и не нужны эти предсказания сами по себе. Поэтому:\n",
    "### 3.1 предложите способ предсказать результаты нового турнира с известными составами, но неизвестными вопросами, в виде ранжирования команд;\n",
    "### 3.2 в качестве метрики качества на тестовом наборе давайте считать ранговые корреляции Спирмена и Кендалла (их можно взять в пакете scipy) между реальным ранжированием в результатах турнира и предсказанным моделью, усреднённые по тестовому множеству турниров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution:\n",
    "### 1) Let's choose random question from our database of questions (mask in results table + tournament id)\n",
    "### 2) On this question our commands will answer (probability of team asnwer question): \n",
    "$ 1 - \\prod_{i \\in S} (1 - f(Player Level, Random Question))$, where $f = \\frac{1}{1 + exp^{-x}}$, S = set of players in team\n",
    "### 3) Let's calculate average of our metrics (Spearman and Kendall Correlations) for every team\n",
    "### 4) Make n iterations of steps 1-3 and calculate averages of defined metrics\n",
    "### 5) For this taks due to time consuming calculations it was used 10 as number of iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result (metrics are approximately in interval that were mentioned in task):\n",
    "#### BASELINE METRICS:\n",
    "#### Spearman Correlation: 78.96% (70% - 80%)\n",
    "#### Kendall Correlation:     63.07% (50% - 60%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Теперь главное: ЧГК — это всё-таки командная игра. Поэтому:\n",
    "### 4.1 предложите способ учитывать то, что на вопрос отвечают сразу несколько игроков; скорее всего, понадобятся скрытые переменные; не стесняйтесь делать упрощающие предположения, но теперь переменные “игрок X ответил на вопрос Y” при условии данных должны стать зависимыми для игроков одной и той же команды;\n",
    "### 4.2 разработайте EM-схему для обучения этой модели, реализуйте её в коде;\n",
    "### 4.3 обучите несколько итераций, убедитесь, что целевые метрики со временем растут (скорее всего, ненамного, но расти должны), выберите лучшую модель, используя целевые метрики."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) E STEP: \n",
    "\n",
    "$Z_i{}_j = 0$, if question is unanswered so if player $i$ gives wrong answer then whole team gives wrong answer on question $j$\n",
    "\n",
    "$Z_i{}_j = \\frac{f(Player Level, Random Question)}{P(Team)}$, where $f = \\frac{1}{1 + exp^{-x}}$, $P(Team)$ - found probability on previous step.\n",
    "\n",
    "2) M STEP: \n",
    "\n",
    "Build logistic model on previos step derived Z.\n",
    "\n",
    "3) Make 10 iterations of steps E and M\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result:\n",
    "### Sometimes on particuar iteration we have worse results than earlier, but with time metrics become better and in final:\n",
    "### Best model achived on:  7th iteration (out of 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. А что там с вопросами? Постройте “рейтинг-лист” турниров по сложности вопросов. Соответствует ли он интуиции (например, на чемпионате мира в целом должны быть сложные вопросы, а на турнирах для школьников — простые)? Если будет интересно: постройте топ сложных и простых вопросов со ссылками на конкретные записи в базе вопросов ЧГК (это чисто техническое дело, тут никакого ML нету)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result:\n",
    "#### 1) Top 10 Tournaments\n",
    "\n",
    "#### Чемпионат Санкт-Петербурга. Первая лига\n",
    "#### 'Первенство правого полушария'\n",
    "#### 'Угрюмый Ёрш'\n",
    "#### 'Кубок городов'\n",
    "#### 'Чемпионат России'\n",
    "#### 'Синхрон высшей лиги Москвы'\n",
    "#### 'All Cats Are Beautiful'\n",
    "#### 'Ра-II: синхрон \"Борского корабела\"'\n",
    "#### 'Антибинго'\n",
    "#### 'Ускользающая сова'\n",
    "\n",
    "#### 2) Bottom 10 Tournaments:\n",
    "\n",
    "#### '(а)Синхрон-lite. Лига старта. Эпизод X'\n",
    "#### 'Второй тематический турнир имени Джоуи Триббиани'\n",
    "#### 'Синхрон-lite. Выпуск XXIX'\n",
    "#### 'Парный асинхронный турнир ChGK is...'\n",
    "#### '(а)Синхрон-lite. Лига старта. Эпизод IX'\n",
    "#### '(а)Синхрон-lite. Лига старта. Эпизод III'\n",
    "#### '(а)Синхрон-lite. Лига старта. Эпизод VI'\n",
    "#### 'Синхрон-lite. Выпуск XXX'\n",
    "#### 'Асинхрон по «Королю и Шуту»'\n",
    "#### '(а)Синхрон-lite. Лига старта. Эпизод V'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CODES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create lists of players and questions among different tournaments and their results description\n",
    "def qsts_plrs_base_databases (tourn, res, flag, mask_flag, members, player_flag, ids, tourn_id, team_id, plr_id, team, pos):\n",
    "  \n",
    "    questions_base, players_base, base, test = [], [], [], []\n",
    "    \n",
    "    for i in tourn.index:\n",
    "        trn_res, number_qsts, mask, data_tourn = res[i], set(), \"\", []\n",
    "    \n",
    "        for word in res[i]:\n",
    "            if word.get(mask_flag) is not None:\n",
    "                number_qsts.add(len(\"\".join(filter(str.isdigit, word[mask_flag]))))\n",
    "\n",
    "        if len(number_qsts) > 1:\n",
    "            continue\n",
    "            \n",
    "        for word in trn_res:\n",
    "            record = {}\n",
    "            if word.get(mask_flag) is not None and word.get(members) is not None:\n",
    "                if word[members] != []:                    \n",
    "                    if flag == 'test':\n",
    "                        mask = \"\".join(filter(str.isdigit, word[mask_flag]))\n",
    "                        record[tourn_id], record[team_id], record[mask_flag], record[plr_id], record[pos]  = i, word.get(team).get(ids), list(map(int, mask)), [], word[pos]\n",
    "                        players = word[members]\n",
    "                        for player in players:\n",
    "                            record[plr_id].append(player[player_flag][ids])\n",
    "                        data_tourn.append(record)\n",
    "                    else:\n",
    "                        mask, players = \"\".join(filter(str.isdigit, word[mask_flag])), word[members]\n",
    "                        record[tourn_id], record[team_id], record[mask_flag], record[plr_id]  = i, word.get(team).get(ids), list(map(int, mask)), []\n",
    "                        for player in players:\n",
    "                            record[plr_id].append(player[player_flag][ids])\n",
    "                            players_base.append(player[player_flag][ids]) \n",
    "                        base.append(record)\n",
    "        \n",
    "        if flag == 'test':\n",
    "            if mask:\n",
    "                test.append(data_tourn)\n",
    "\n",
    "        for j, k in enumerate(mask):\n",
    "               questions_base.append(str(i) + \"-\" + str(j))\n",
    "                \n",
    "    if flag == 'train':\n",
    "        return questions_base, players_base, base\n",
    "    else:\n",
    "        return questions_base, players_base, test\n",
    "questions_base, players_base, base = qsts_plrs_base_databases(df_train_tournaments, results, 'train', 'mask', 'teamMembers', 'player', 'id', 'tournament_id', 'team_id', 'players_id', 'team', 'position')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_base, players_base, base = qsts_plrs_base_databases(df_train_tournaments, results, 'train', 'mask', 'teamMembers', 'player', 'id', 'tournament_id', 'team_id', 'players_id', 'team', 'position')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder_plrs, Encoder_qsts  = OneHotEncoder(), OneHotEncoder()\n",
    "players_base_encoded        = Encoder_plrs.fit_transform(np.array(players_base).reshape(-1, 1))\n",
    "questions_base_encoded      = Encoder_qsts.fit_transform(np.array(questions_base).reshape(-1, 1))\n",
    "\n",
    "def Logistic_Regression_Training_With_Encoders(df, flag_1, flag_2, flag_3):\n",
    "\n",
    "    features, labels = [], []\n",
    "    for record in df:\n",
    "        if record != {}:\n",
    "\n",
    "            idx, mask, plr_idx, trn_qstn = str(record[flag_1]), record[flag_2], record[flag_3], []    \n",
    "            matrix_plr = Encoder_plrs.transform(np.array([np.full((len(mask), ), k) for k in plr_idx]).reshape(-1, 1))\n",
    "\n",
    "            for j in range(len(mask)):\n",
    "                trn_qstn.append(idx + \"-\" + str(j))\n",
    "\n",
    "            matrix_qsts = Encoder_qsts.transform(np.tile(trn_qstn, len(plr_idx)).reshape(-1, 1))\n",
    "            labels.append(np.tile(mask, len(plr_idx)).reshape(-1, 1))\n",
    "            features.append(hstack([matrix_plr, matrix_qsts]))\n",
    "\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(vstack(features), \n",
    "               np.vstack(labels))\n",
    "    \n",
    "    return vstack(features), np.vstack(labels), logreg\n",
    "\n",
    "features, labels, logreg = Logistic_Regression_Training_With_Encoders(base, 'tournament_id', 'mask', 'players_id')\n",
    "\n",
    "def dict_players(df, flag):\n",
    "    \n",
    "    plrs = []\n",
    "    for record in df:\n",
    "         if record != {}:\n",
    "            for idx in record[flag]:\n",
    "                   if idx not in plrs:\n",
    "                        plrs.append(idx)\n",
    "    return plrs\n",
    "\n",
    "plrs = dict_players(base, 'players_id')\n",
    "\n",
    "def table_with_players_rating(df, flag_1, flag_2, flag_3):\n",
    "    \n",
    "    Rating               = pd.DataFrame({flag_1: sorted(plrs), 'Rating': log_reg.coef_[0][:len(plrs)]})\n",
    "    number_games_per_plr = Counter()\n",
    "    for record in df:\n",
    "        if record != {}:\n",
    "            for idx in record[flag_3]:\n",
    "                number_games_per_plr[idx] += len(record[flag_2])\n",
    "            \n",
    "    Games_Number = pd.DataFrame.from_dict(number_games_per_plr, orient='index')\n",
    "    Games_Number[flag_1] = Games_Number.index\n",
    "    Rating = df_players_indexed.merge(Rating, on=flag_1)\n",
    "    Rating = Rating.merge(Games_Number, on=flag_1)\n",
    "    print(Rating.sort_values(by='Rating', ascending=False).head(30))\n",
    "    return Rating\n",
    "\n",
    "Rating = table_with_players_rating(base, 'player_id', 'mask', 'players_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, base_test = qsts_plrs_base_databases(df_test_tournaments, results, \"test\", \"mask\", \"teamMembers\", \"player\", \"id\", \"tournament_id\", \"team_id\", \"players_id\", \"team\", \"position\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_team_rating_Spearman_Kendall(df, model, pos, plrs, team, tourn, qst):\n",
    "    \n",
    "    test_res = {}\n",
    "   \n",
    "    for idx in df:\n",
    "        tourn_res = {}\n",
    "        for word in idx:\n",
    "            k = word[pos]\n",
    "            mmbrs = []\n",
    "            for plr_id in word[plrs]:\n",
    "                try:\n",
    "                    Encoder_plrs.transform([[plr_id]])\n",
    "                    mmbrs.append(plr_id)\n",
    "                except ValueError:\n",
    "                    continue   \n",
    "            if mmbrs == []:\n",
    "                continue\n",
    "            matrix_plr, matrix_qsts  = Encoder_plrs.transform(np.array(mmbrs).reshape(-1, 1)), Encoder_qsts.transform(np.full((len(mmbrs), 1), qst))\n",
    "            pred = model.predict_proba(hstack([matrix_plr, matrix_qsts]))[:, 1]\n",
    "            tourn_res[word[team]] = (1 - np.product(1 - pred), k)\n",
    "        test_res[idx[0][tourn]] = tourn_res\n",
    "    \n",
    "    sp_corr, ken_corr  = [], []\n",
    "    \n",
    "    for idx in test_res.values():\n",
    "        pred, k = [], []\n",
    "        for i in idx.values():\n",
    "            pred.append(i[0])\n",
    "            k.append(i[1])\n",
    "        sp_corr.append(spearmanr(pred, k)[0])\n",
    "        ken_corr.append(kendalltau(pred, k)[0])\n",
    "    \n",
    "    return np.nanmean(np.abs(sp_corr)), np.nanmean(np.abs(ken_corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1 Spearman Correlation:  0.7873801114705261 Kendall Correlation:  0.6278180169776942\n",
      "Iteration:  2 Spearman Correlation:  0.7933366182232459 Kendall Correlation:  0.6347137343408068\n",
      "Iteration:  3 Spearman Correlation:  0.7943439199792 Kendall Correlation:  0.6362151561649261\n",
      "Iteration:  4 Spearman Correlation:  0.7904519078919052 Kendall Correlation:  0.6312738479637523\n",
      "Iteration:  5 Spearman Correlation:  0.7943798073121919 Kendall Correlation:  0.6362406503683327\n",
      "Iteration:  6 Spearman Correlation:  0.7926932115998585 Kendall Correlation:  0.6340849730380285\n",
      "Iteration:  7 Spearman Correlation:  0.7723488573135294 Kendall Correlation:  0.6126339864684278\n",
      "Iteration:  8 Spearman Correlation:  0.7915019977653975 Kendall Correlation:  0.6326936590367839\n",
      "Iteration:  9 Spearman Correlation:  0.7860364481448148 Kendall Correlation:  0.6265755629369366\n",
      "Iteration:  10 Spearman Correlation:  0.7932143816070908 Kendall Correlation:  0.6346547201195544\n"
     ]
    }
   ],
   "source": [
    "number_iter = 10\n",
    "res = []\n",
    "for i in range(number_iter):\n",
    "    qst = random.choice(questions_base)\n",
    "    sp, ke = predict_team_rating_Spearman_Kendall(base_test, logreg, 'position', 'players_id', 'team_id' , 'tournament_id', qst)\n",
    "    print('Iteration: ', i + 1, 'Spearman Correlation: ', sp, 'Kendall Correlation: ', ke)\n",
    "    res.append([sp, ke])\n",
    "res = np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINE METRICS:\n",
      "Spearman Correlation: 0.789568726130776\n",
      "Kendall Correlation: 0.6306904307415244\n"
     ]
    }
   ],
   "source": [
    "print('BASELINE METRICS:')\n",
    "print('Spearman Correlation:', np.mean(res, axis = 0)[0])\n",
    "print('Kendall Correlation:',  np.mean(res, axis = 0)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EM_ALGORITHM (logreg, features, labels, Z, flag):\n",
    "    \n",
    "    if flag == 'E':\n",
    "        \n",
    "        print('E STEP')\n",
    "        \n",
    "        preds, idx = logreg.predict_proba(features)[:, 1], 0\n",
    "        \n",
    "        for record in base:\n",
    "            \n",
    "            preds_team          = preds[idx : idx + len(record[\"players_id\"]) * len(record[\"mask\"])]\n",
    "            response_team       = preds[idx : idx + len(record[\"players_id\"]) * len(record[\"mask\"])]\n",
    "            right_response_team = labels[idx: idx + len(record[\"mask\"])]\n",
    "            response_team       = response_team.reshape((-1, len(record[\"mask\"]))).T\n",
    "            vector              = 1 - np.prod(1 - response_team, axis=1)\n",
    "            response_team       = response_team / vector.reshape(-1, 1)\n",
    "            response_team       = np.where(right_response_team != 0, response_team, 0)\n",
    "            preds[idx: idx + len(record[\"players_id\"]) * len(record[\"mask\"])] = response_team.T.reshape(-1) \n",
    "            idx                 = idx + len(record[\"players_id\"]) * len(record[\"mask\"])   \n",
    "    \n",
    "        return preds\n",
    "    \n",
    "    else: \n",
    "        \n",
    "        print('M STEP')\n",
    "        \n",
    "        labels, inputs = np.vstack((np.full((features.shape[0], 1), 0), np.full((features.shape[0], 1), 1))), vstack([features, features])\n",
    "        weights        = np.hstack((1 - Z, Z))\n",
    "        model          = LogisticRegression()\n",
    "        model.fit(inputs, labels, sample_weight=weights)\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1\n",
      "E STEP\n",
      "M STEP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DE118048\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\DE118048\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation:  0.7790439557600213 Kendall Correlation:  0.6204891541676517\n",
      "Iteration:  2\n",
      "E STEP\n",
      "M STEP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DE118048\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\DE118048\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation:  0.7710685972094713 Kendall Correlation:  0.6122779382318523\n",
      "Iteration:  3\n",
      "E STEP\n",
      "M STEP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DE118048\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\DE118048\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation:  0.7726572059853791 Kendall Correlation:  0.6138552944219076\n",
      "Iteration:  4\n",
      "E STEP\n",
      "M STEP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DE118048\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\DE118048\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation:  0.7776784829962957 Kendall Correlation:  0.6193075666968156\n",
      "Iteration:  5\n",
      "E STEP\n",
      "M STEP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DE118048\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\DE118048\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation:  0.7796262891709009 Kendall Correlation:  0.6217908532270977\n",
      "Iteration:  6\n",
      "E STEP\n",
      "M STEP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DE118048\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\DE118048\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation:  0.7818274820376722 Kendall Correlation:  0.624437957930259\n",
      "Iteration:  7\n",
      "E STEP\n",
      "M STEP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DE118048\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\DE118048\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation:  0.7776042716050733 Kendall Correlation:  0.6201581800653587\n",
      "Iteration:  8\n",
      "E STEP\n",
      "M STEP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DE118048\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\DE118048\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation:  0.7836459166311835 Kendall Correlation:  0.6272008792567701\n",
      "Iteration:  9\n",
      "E STEP\n",
      "M STEP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DE118048\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\DE118048\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation:  0.7782953773596344 Kendall Correlation:  0.6225062012672502\n",
      "Iteration:  10\n",
      "E STEP\n",
      "M STEP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DE118048\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\DE118048\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation:  0.7817081236144051 Kendall Correlation:  0.6264545437050248\n"
     ]
    }
   ],
   "source": [
    "number_iter = 10\n",
    "res, question = [], qst\n",
    "model, list_of_models = logreg, []\n",
    "for i in range(number_iter):\n",
    "    print('Iteration: ', i + 1)\n",
    "    Z      = EM_ALGORITHM(model, features, labels, _ , 'E')\n",
    "    model  = EM_ALGORITHM(_,      features, _,      Z,  'M')\n",
    "    list_of_models.append(model)\n",
    "    sp, ke = predict_team_rating_Spearman_Kendall(base_test, model, 'position', 'players_id', 'team_id' , 'tournament_id', question)\n",
    "    print('Spearman Correlation: ', sp, 'Kendall Correlation: ', ke)\n",
    "    res.append([sp, ke])\n",
    "res = np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model achived on:  7 iteration\n"
     ]
    }
   ],
   "source": [
    "i_max = 0\n",
    "maxx  = 0\n",
    "for i in range(len(res)):\n",
    "    if np.mean(res[i]) > maxx:\n",
    "        i_max = i\n",
    "        maxx = np.mean(res[i], axis = 0)\n",
    "print('Best model achived on: ', i_max, 'iteration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = list_of_models[i_max]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tourn_rankig(df, tourn, mask_flag, model):\n",
    "\n",
    "    lst = [[df[0][tourn], len(df[0][mask_flag])]]\n",
    "    for record in df:\n",
    "        idx = record[tourn]\n",
    "        if lst[-1] != [idx, len(record[mask_flag])]:\n",
    "            lst.append([idx, len(record[mask_flag])])\n",
    "\n",
    "    qst_level, tourn_level  = model.coef_[0][len(plrs):], []\n",
    "    tourn_level = []\n",
    "    k = 0\n",
    "    for record in lst:\n",
    "        temp = np.array(qst_level[k : k + record[1]])\n",
    "        tourn_level.append([record[0], np.mean(temp)])\n",
    "        k = k + record[1]\n",
    "        \n",
    "    return tourn_level\n",
    "\n",
    "# use best model predictions derived on previous step for defining tournament level\n",
    "tourn_level = tourn_rankig(base, 'tournament_id', 'mask', best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Чемпионат Санкт-Петербурга. Первая лига\n",
      "Первенство правого полушария\n",
      "Угрюмый Ёрш\n",
      "Кубок городов\n",
      "Чемпионат России\n",
      "Синхрон высшей лиги Москвы\n",
      "All Cats Are Beautiful\n",
      "Ра-II: синхрон \"Борского корабела\"\n",
      "Антибинго\n",
      "Ускользающая сова\n"
     ]
    }
   ],
   "source": [
    "# top 10 tournaments\n",
    "\n",
    "k = 10\n",
    "for i in sorted(tourn_level, key=lambda x: x[1])[:k]:\n",
    "    print(df_train_tournaments.loc[i[0]]['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(а)Синхрон-lite. Лига старта. Эпизод X\n",
      "Второй тематический турнир имени Джоуи Триббиани\n",
      "Синхрон-lite. Выпуск XXIX\n",
      "Парный асинхронный турнир ChGK is...\n",
      "(а)Синхрон-lite. Лига старта. Эпизод IX\n",
      "(а)Синхрон-lite. Лига старта. Эпизод III\n",
      "(а)Синхрон-lite. Лига старта. Эпизод VI\n",
      "Синхрон-lite. Выпуск XXX\n",
      "Асинхрон по «Королю и Шуту»\n",
      "(а)Синхрон-lite. Лига старта. Эпизод V\n"
     ]
    }
   ],
   "source": [
    "# bottom 10 tournamments\n",
    "\n",
    "for i in sorted(tourn_level, key=lambda x: x[1])[-k:]:\n",
    "    print(df_train_tournaments.loc[i[0]]['name'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
